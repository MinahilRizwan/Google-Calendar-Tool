{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain openai\n"
      ],
      "metadata": {
        "id": "u2F-v46Qn805"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-experimental\n"
      ],
      "metadata": {
        "id": "xlNXr_u6oLYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain openai langchain-experimental\n"
      ],
      "metadata": {
        "id": "v6erP6nMoP5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZWBq58fy9QZ"
      },
      "outputs": [],
      "source": [
        "!pip install -U langchain langgraph google-api-python-client langchain[google-genai]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def _set_env(key):\n",
        "    value = os.environ.get(key)\n",
        "    if value is None:\n",
        "        value = input(f\"Please enter your {key}: \")\n",
        "        os.environ[key] = value\n",
        "\n",
        "# Set keys\n",
        "_set_env(\"GOOGLE_API_KEY\")   # From Google Cloud Console\n",
        "_set_env(\"GOOGLE_CSE_ID\")    # From Programmable Search Engine (CSE)"
      ],
      "metadata": {
        "id": "teeYhUTdzEKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import Tool\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "def google_search(query: str, max_results: int = 3):\n",
        "    service = build(\"customsearch\", \"v1\", developerKey=os.environ[\"GOOGLE_API_KEY\"])\n",
        "    res = service.cse().list(q=query, cx=os.environ[\"GOOGLE_CSE_ID\"], num=max_results).execute()\n",
        "    results = res.get(\"items\", [])\n",
        "    return \"\\n\".join([f\"{item['title']}: {item['link']}\" for item in results])\n",
        "\n",
        "# Wrap as a LangChain tool\n",
        "google_tool = Tool(\n",
        "    name=\"GoogleSearch\",\n",
        "    func=google_search,\n",
        "    description=\"Use this tool to search the web using Google Search\"\n",
        ")\n",
        "\n",
        "tools = [google_tool]"
      ],
      "metadata": {
        "id": "b5ui0rtTz-TB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain openai google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client\n"
      ],
      "metadata": {
        "id": "RWhFwW-Jo_ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from langchain.agents import Tool\n",
        "from langchain.agents.agent_toolkits import create_retriever_tool\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain.chains.llm_math.base import LLMMathChain\n"
      ],
      "metadata": {
        "id": "GMULXuQDqD7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain.tools\n",
        "dir(langchain.tools)\n"
      ],
      "metadata": {
        "id": "pdZAWygSqQ8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from langchain.agents import create_openai_functions_agent\n",
        "from langchain.agents import AgentExecutor\n",
        "from langchain.agents import Tool\n",
        "from google.auth.transport.requests import Request\n",
        "from google.oauth2.service_account import Credentials\n",
        "from googleapiclient.discovery import build\n"
      ],
      "metadata": {
        "id": "PNOotlF_pFTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.oauth2 import service_account\n",
        "from googleapiclient.discovery import build\n",
        "import datetime\n",
        "\n",
        "# Path to your service account key file\n",
        "SERVICE_ACCOUNT_FILE = '/content/credentials.json'\n",
        "\n",
        "# Scopes required for Google Calendar\n",
        "SCOPES = ['https://www.googleapis.com/auth/calendar.readonly']\n",
        "\n",
        "# Authenticate\n",
        "credentials = service_account.Credentials.from_service_account_file(\n",
        "    SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
        "\n",
        "# Build the service\n",
        "service = build('calendar', 'v3', credentials=credentials)\n",
        "\n",
        "# Get upcoming events\n",
        "now = datetime.datetime.utcnow().isoformat() + 'Z'\n",
        "events_result = service.events().list(\n",
        "    calendarId='primary', timeMin=now,\n",
        "    maxResults=5, singleEvents=True,\n",
        "    orderBy='startTime').execute()\n",
        "events = events_result.get('items', [])\n",
        "\n",
        "for event in events:\n",
        "    start = event['start'].get('dateTime', event['start'].get('date'))\n",
        "    print(start, event['summary'])\n"
      ],
      "metadata": {
        "id": "C88r5hmTyJuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wrap Calendar code in a Function"
      ],
      "metadata": {
        "id": "ljYPzMVqGZ0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_upcoming_events():\n",
        "    from google.oauth2 import service_account\n",
        "    from googleapiclient.discovery import build\n",
        "    import datetime\n",
        "\n",
        "    SERVICE_ACCOUNT_FILE = '/content/inbound-credentials.json'\n",
        "    SCOPES = ['https://www.googleapis.com/auth/calendar.readonly']\n",
        "\n",
        "    credentials = service_account.Credentials.from_service_account_file(\n",
        "        SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
        "\n",
        "    service = build('calendar', 'v3', credentials=credentials)\n",
        "\n",
        "    now = datetime.datetime.utcnow().isoformat() + 'Z'\n",
        "    events_result = service.events().list(\n",
        "        calendarId='primary', timeMin=now,\n",
        "        maxResults=5, singleEvents=True,\n",
        "        orderBy='startTime').execute()\n",
        "    events = events_result.get('items', [])\n",
        "\n",
        "    if not events:\n",
        "        return \"No upcoming events found.\"\n",
        "\n",
        "    response = \"\"\n",
        "    for event in events:\n",
        "        start = event['start'].get('dateTime', event['start'].get('date'))\n",
        "        summary = event.get('summary', 'No title')\n",
        "        response += f\"{start}: {summary}\\n\"\n",
        "    return response.strip()\n"
      ],
      "metadata": {
        "id": "eQUEoG2ozXqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Turning a function of calendar into langchain tool"
      ],
      "metadata": {
        "id": "RuP_qrKRGdoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import Tool\n",
        "\n",
        "calendar_tool = Tool(\n",
        "    name=\"Google Calendar\",\n",
        "    func=lambda _: get_upcoming_events(),\n",
        "    description=\"Use this to check upcoming calendar events.\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "BS8B2zp6zb-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add Tool to the Agent\n"
      ],
      "metadata": {
        "id": "AXZ3J-PMGlJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain langchain-community google-auth google-api-python-client\n",
        "\n",
        "import os\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.tools import Tool\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Optional: Set API key environment variables (if not set elsewhere)\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"your api key here\"  # Replace with actual key\n",
        "\n",
        "# 1. Initialize the Gemini model\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0)\n",
        "\n",
        "# 2. Define a dummy calendar tool for testing (replace with real implementation)\n",
        "def dummy_calendar_tool(query: str) -> str:\n",
        "    return \"You have a meeting today at 3 PM.\"\n",
        "\n",
        "calendar_tool = Tool(\n",
        "    name=\"GoogleCalendarTool\",\n",
        "    func=dummy_calendar_tool,\n",
        "    description=\"Useful for checking calendar events.\"\n",
        ")\n",
        "\n",
        "# 3. Initialize the agent\n",
        "agent = initialize_agent(\n",
        "    tools=[calendar_tool],\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# 4. Run agent with a user prompt\n",
        "response = agent.run(\"Do I have any meetings today?\")\n",
        "print(\"\\nFinal Response:\\n\", response)\n"
      ],
      "metadata": {
        "id": "BLiei7H4zgfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "# If not already set\n",
        "os.environ[\"GOOGLE_API_KEY\"] = os.environ.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "# Initialize Gemini model\n",
        "llm = init_chat_model(\"google_genai:gemini-2.0-flash\")\n",
        "llm_with_tools = llm.bind_tools(tools)"
      ],
      "metadata": {
        "id": "zcMYsoJ40C5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "# If not already set\n",
        "os.environ[\"GOOGLE_API_KEY\"] =\"your api key here\"\n",
        "os.environ.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "# Initialize Gemini model\n",
        "llm = init_chat_model(\"google_genai:gemini-2.0-flash\")\n",
        "llm_with_tools = llm.bind_tools(tools)"
      ],
      "metadata": {
        "id": "RWL6MOC-0GNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)"
      ],
      "metadata": {
        "id": "hI5FohvP0Pha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from langchain_core.messages import ToolMessage\n",
        "\n",
        "class BasicToolNode:\n",
        "    def __init__(self, tools: list) -> None:\n",
        "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
        "\n",
        "    def __call__(self, inputs: dict):\n",
        "        if messages := inputs.get(\"messages\", []):\n",
        "            message = messages[-1]\n",
        "        else:\n",
        "            raise ValueError(\"No message found in input\")\n",
        "        outputs = []\n",
        "        for tool_call in message.tool_calls:\n",
        "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
        "                tool_call[\"args\"]\n",
        "            )\n",
        "            outputs.append(\n",
        "                ToolMessage(\n",
        "                    content=json.dumps(tool_result),\n",
        "                    name=tool_call[\"name\"],\n",
        "                    tool_call_id=tool_call[\"id\"],\n",
        "                )\n",
        "            )\n",
        "        return {\"messages\": outputs}\n",
        "\n",
        "tool_node = BasicToolNode(tools=[google_tool])\n",
        "graph_builder.add_node(\"tools\", tool_node)"
      ],
      "metadata": {
        "id": "eFmVszKi0VHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def route_tools(state: State):\n",
        "    if isinstance(state, list):\n",
        "        ai_message = state[-1]\n",
        "    elif messages := state.get(\"messages\", []):\n",
        "        ai_message = messages[-1]\n",
        "    else:\n",
        "        raise ValueError(\"No messages found in input state to tool_edge: {state}\")\n",
        "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
        "        return \"tools\"\n",
        "    return END\n",
        "\n",
        "graph_builder.add_conditional_edges(\"chatbot\", route_tools, {\"tools\": \"tools\", END: END})\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "gHVld2ZT0Z3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def _set_env(key):\n",
        "    value = os.environ.get(key)\n",
        "    if value is None:\n",
        "        value = input(f\"Please enter your {key}: \")\n",
        "        os.environ[key] = value\n",
        "\n",
        "# Set keys\n",
        "_set_env(\"GOOGLE_API_KEY\")   # From Google Cloud Console\n",
        "_set_env(\"GOOGLE_CSE_ID\")    # From Programmable Search Engine (CSE)"
      ],
      "metadata": {
        "id": "btzQjTFX15qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace complex graph definition with minimal one for fast reply\n",
        "from langgraph.graph import StateGraph\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "def simple_llm_node(state):\n",
        "    user_input = state[\"messages\"][-1][\"content\"]\n",
        "    response = {\"role\": \"assistant\", \"content\": f\"Echo: {user_input}\"}\n",
        "    return {\"messages\": state[\"messages\"] + [response]}\n",
        "\n",
        "# Pass the State type object for `StateGraph`\n",
        "graph = StateGraph(State)\n",
        "graph.add_node(\"echo\", RunnableLambda(simple_llm_node))\n",
        "graph.set_entry_point(\"echo\")\n",
        "graph.set_finish_point(\"echo\")\n",
        "graph = graph.compile()"
      ],
      "metadata": {
        "id": "lv-vBXks4GKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "\n",
        "async def stream_graph_updates_async(user_input: str):\n",
        "    print(\"Assistant: \", end='', flush=True)\n",
        "    async for event in graph.astream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
        "        message = event.get(\"messages\", [])\n",
        "        if message:\n",
        "            content = message[-1].get(\"content\", \"\")\n",
        "            if content:\n",
        "                sys.stdout.write(content)\n",
        "                sys.stdout.flush()\n",
        "    print()\n",
        "\n",
        "async def main_async():\n",
        "    while True:\n",
        "        user_input = input(\"User: \")\n",
        "        if user_input.lower() in [\"exit\", \"quit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "        await stream_graph_updates_async(user_input)\n",
        "\n",
        "# Instead of asyncio.run(), get the current event loop and run the coroutine until it completes\n",
        "loop = asyncio.get_event_loop()\n",
        "# Check if the loop is already running, if not, run it forever\n",
        "if not loop.is_running():\n",
        "    try:\n",
        "        loop.run_until_complete(main_async())\n",
        "    finally:\n",
        "        loop.close()\n",
        "else:\n",
        "    # If the loop is already running, schedule the coroutine to be executed\n",
        "    asyncio.ensure_future(main_async())"
      ],
      "metadata": {
        "id": "rkBzevAO4O0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "def stream_graph_updates(user_input: str):\n",
        "    print(\"Assistant: \", end='', flush=True)\n",
        "    try:\n",
        "        for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
        "            message = event.get(\"messages\", [])\n",
        "            if message:\n",
        "                content = message[-1].get(\"content\", \"\")\n",
        "                if content:\n",
        "                    sys.stdout.write(content)\n",
        "                    sys.stdout.flush()\n",
        "        print()  # Newline after response finishes\n",
        "    except Exception as e:\n",
        "        print(f\"\\n[Error while streaming response: {e}]\")\n",
        "\n",
        "def main():\n",
        "    while True:\n",
        "        try:\n",
        "            user_input = input(\"User: \")\n",
        "            if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "                print(\"Goodbye!\")\n",
        "                break\n",
        "            stream_graph_updates(user_input)\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\nGoodbye!\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"\\nUnexpected error: {e}\")\n",
        "            break\n",
        "\n",
        "main()\n"
      ],
      "metadata": {
        "id": "o15qrMe94fOj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}